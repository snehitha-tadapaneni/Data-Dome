---
title: "DATS 6101 - Midterm"
output: html_document
date: "`r Sys.Date()`"
author: "Name: Snehitha Tadapaneni, Sai Rachana Kandikattu, Amrutha Jayachandradhara, Wilona Nguyen, Pramod Krishnachari
"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = F, results = "markdown", message = F)
```

# Introduction

Our research focuses on performing Exploratory Data Analysis (EDA) on
Google Play Store apps to uncover patterns, trends, and insights
regarding app characteristics, user behavior, and installation patterns.
We are trying to see how app popularity, defined as the number of
installs with high reviews and ratings, is impacted by categories, last
updated, app sizes, version, and other factors.

# Smart Question

“What is the impact of content rating, required Android version, app
category, size, and pricing on predicting app success in terms of
positive ratings and high user reviews, as well as the number of
installs, using data from Google Play Store apps from 2010 to 2018?”

> *Specific*: The question clearly defines the variables (content
> rating, required Android version, app category, size, pricing) and the
> outcomes (positive ratings, high user reviews, number of installs).
>
> *Measurable*: The outcomes (positive ratings, high user reviews,
> number of installs) are quantifiable.
>
> *Achievable*: Given the availability of Google Play Store data from
> 2010 to 2018, the analysis is feasible.
>
> *Relevant*: The question addresses a significant issue in the app
> development and marketing industry: predicting app success.
>
> *Time-specific*: The timeframe (2010-2018) is clearly defined.

```{r required libraries, include=F}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Importing the necessary libraries
library(ezids)
library(dplyr)
library(ggplot2)
library(DT)
library(corrplot)
library(lubridate)
library(tidyr)
library(scales)
library(cluster)
library(knitr)
library(kableExtra)
library(hexbin)
```

# Data Preparation and Cleaning

Here, we have loaded the dataset 'Google Play Store Apps' stored in csv file using ()

```{r}
#Loading the Dataset
data_apps <- data.frame(read.csv("googleplaystore.csv"))
```

```{r}
#Checking the structure of the data
str(data_apps)
```


```{r}
#First 5 rows of the dataset
head(data_apps)
```

#### Description of the App Dataset Columns
1) App: The name of the application, represented as a character string.
2) Category: The main category of the app, such as "ART_AND_DESIGN," represented as a character string.
3) Rating: The average user rating of the app, recorded as a numeric value.
4) Reviews: The total number of user reviews for the app, shown as a character string.
5) Size: The size of the application, represented as a character string.
6) Installs: The approximate number of installations for the app, stored as a character string.
7) Type: Indicates whether the app is free or paid, represented as a character string.
8) Price: The price of the app, stored as a character string. Free apps are listed as "0," while paid apps have a dollar amount.
9) Content.Rating: The target age group for the app, represented as a character string.
10) Genres: The genre(s) of the app.
11) Last.Updated: The date of the app's last update, stored as a character string.
12) Current.Ver: The current version of the app, represented as a character string.
13) Android.Ver: The minimum Android version required to run the app, stored as a character string.


## Apps

```{r ST0}
# Checking the type of the App 
typeof(data_apps$App)
```

#### Checking for duplicated apps and removing

```{r}
#Display all the duplicated Apps
duplicate_apps <- aggregate(App ~ ., data = data_apps, FUN = length)  
duplicate_apps <- duplicate_apps[duplicate_apps$App > 1, ] 
duplicate_apps <- duplicate_apps[order(-duplicate_apps$App), ] 

#View(duplicate_apps)
#print(duplicate_apps)

print(paste("Number of duplicated Apps:",nrow(duplicate_apps)))

#Removing Na values and duplicates
data_clean <- data_apps[!is.na(data_apps$App), ] 
data_clean <- data_clean[!duplicated(data_clean$App), ] 

#(After removing the duplicates) Unique values
unique_apps <- length(unique(data_clean$App))
print(paste("Number of unique apps after removing the duplicates:", unique_apps))

```

Duplicate App Analysis:

* 404 apps were repeated either twice or thrice.
* After removing duplicates, the dataset now contains 9660 unique apps.
* Total duplicates removed: 1181 apps.

#### After dropping duplicate

```{r}
str(data_clean$App)
```

## Price

```{r ST1}
typeof(data_apps$Price)
```

#### Convertion of Price to numerical 
There is '$' present after each price of the App. Check and remove before conversion.

```{r}
#To check if there is dollar symbol present 
#data_clean$Price[]
```

```{r}
# Remove dollar symbols and convert to numeric
data_clean$Price <- as.numeric(gsub("\\$", "", data_clean$Price))
```

```{r}
#Recheck for dollar symbol
#data_clean$Price[]
```
All the dollar symbols are removed succesfully.
```{r}
# Summary statistics for price
summary(data_clean$Price)
```

From the unique_df, there is a missing value present in the Price column. Let's handle it!

#### Checking for missing values in Price

```{r}
missing_na <- is.na(data_clean$Price)    
missing_blank <- data_clean$Price == "" 

sum(missing_na)
sum(missing_blank, na.rm = TRUE)
```

```{r}
# Remove row where Price is NA or blank
data_clean <- data_clean[!is.na(data_clean$Price) & data_clean$Price != "", ]
```

Have removed one row #10473 which app does not have a category nameas it is not relevant to our analysis.

```{r}
#Recheck for missing values
summary(data_clean$Price)
```

##### Missing values removed succesfully. (Price)


## Type

```{r ST2}
#Checking the type of Type variable
table(data_clean$Type)
```
From the price column, we can see 8903 apps are free but it is misread somewhere in the Type column. So lets check!
```{r}
#Checking for Missing values
print(paste("Missing values:",sum(is.na(data_clean$Type))))

data_clean[is.na(data_clean$Type), ]

```



```{r}
# Replace NaN or missing values in the Type column with "Free"
data_clean$Type[is.na(data_clean$Type)] <- "Free"
```
There is one row 9150, has a missing value for Type. As the price is 0,
replaced it with "Free".

##### Missing values handles succesfully. (Type)


## Size

```{r}
# Checking the type of the Size 
typeof(data_apps$Size)
```
#### Replacing Misiing values with the mean (Size)
```{r}
# Replace "Varies with Device" in the Size column with NA
data_clean$Size[data_clean$Size == "Varies with device"] <- NA
data_clean <- data_clean[!grepl("\\+", data_clean$Size), ]
data_clean$Size <- ifelse(grepl("k", data_clean$Size),
                          as.numeric(gsub("k", "", data_clean$Size)) *
0.001,  # Convert "K" to MB
                          as.numeric(gsub("M", "", data_clean$Size)))
# Remove "M" for megabytes
# Calculate and display the mean size for each category in the 'Type' column
mean_size_by_type <- tapply(data_clean$Size, data_clean$Category,
mean, na.rm = TRUE)
print(mean_size_by_type)


# Loop through each row and replace NA values in the Size column with the mean size of the corresponding category
data_clean$Size <- ifelse(
  is.na(data_clean$Size),  # Check if Size is NA
  round(mean_size_by_type[data_clean$Category], 1),  # Replace with the mean size based on the Category
  data_clean$Size  # Keep the original size if it's not NA
)

```


## Installs

####Remove the '+' sign, Remove the commas, Convert to numeric

```{r A.J}
#clean installations
clean_installs <- function(Installs) {
  Installs <- gsub("\\+", "", Installs)  
  Installs <- gsub(",", "", Installs)    
  return(as.numeric(Installs))           
}

data_clean$Installs <- sapply(data_clean$Installs, clean_installs)

nan_rows <- sapply(data_clean[, c("Size", "Installs")], function(x) any(is.nan(x)))

# Display only rows that contain NaN in either Size or Installs
data_clean[,nan_rows]


datatable((data_clean), options = list(scrollX = TRUE ))
```

#### Display the unique values

```{r A.J1}
data_clean <- data_clean %>%
  mutate(Rating = ifelse(is.na(Rating), mean(Rating, na.rm = TRUE), Rating))

# Identify the unique values in the 'Installs' column
unique_values <- unique(data_clean$Installs)

# Display the unique values
print(unique_values)

# Function to convert the installs to numeric
convert_to_numeric <- function(x) {
  # Remove non-numeric characters and convert to numeric
  as.numeric(gsub("[^0-9]", "", x)) * 10^(length(gregexpr(",", x)[[1]]) - 1)
}

# Sort unique values based on the custom numeric conversion
sorted_values <- unique_values[order(sapply(unique_values, convert_to_numeric))]


```

## Rating and Reviews

```{r}
# Checking the type of the Rating 
typeof(data_clean$Rating)
```

```{r}
# Checking the type of the Reviews 
typeof(data_clean$Reviews)
```

#### Checking the format of Rating and Reviews

```{r summary statistics, echo=FALSE}
str(data_clean$Reviews)
str(data_clean$Rating)
```

As we can see the Review column is in string format which could be
converted into int for more insights.

#### Checking the unique values for reviews and rating
```{r}
unique_values <- unique(data_clean$Reviews)
unique_values1 <- unique(data_clean$Rating)
# Display the unique values
print(unique_values)
print(unique_values1)
```


#### Change the column reviews from Str to int

```{r , echo=FALSE}
data_clean$Reviews <- as.numeric(data_clean$Reviews)
str(data_clean)
xkablesummary(data_clean)
```

There are 1463 missing values in rating. 



As it could observed the Family category apps have the highest NA values. Let's not drop them but handle them by replacing with the mean value for the category.

#### Checking for Outliers For rating by seeing frequency for each rating

```{r}
 breaks = seq(15,20,by = 1)
frequency_table = table(data_clean$Rating)
frequency_table
```
From above it can be seen all the rating are between 1 and 5.But, most of them are above 4

#### Replacing NA values in Rating with mean
```{r}
#Replace NA in Ratings with Overall Mean
data_clean <- data_clean %>%
  mutate(Rating = ifelse(is.na(Rating), mean(Rating, na.rm = TRUE), Rating))

xkablesummary(data_clean)

```

Now there are no missing values in reviews.



## Category

```{r W}
# Checking the type of the Category 
typeof(data_apps$Category)
```


```{r}
length(unique(data_clean$Category))
length(unique(data_clean$Genres))
```


There are 33 categories in the the data frame with 118 genres. This means
that in each category, there are multiple genres. Given that, the later
analyses in this project can be proceeded with Category variable.

Below is the graph for the distribution of Categories for the dataset
after removing duplicates.


## Current Version & Genres

Due to the inconsistent formatting of values in the `Current.Ver`
column, this column is dropped and will be excluded from the analysis.

```{r}
data_final <- data_clean %>% select(-c('Genres', 'Current.Ver'))
data_final$Category <- as.factor(data_final$Category)
data_final$Android.Ver <- as.factor(data_final$Android.Ver)

```


## Content Rating, Last Updated

```{r}
# Remove leading and trailing spaces and convert all text to a consistent format 
data_final$Content.Rating <- trimws(tolower(data_final$Content.Rating))

cr_missing <- sum(is.na(data_final$`Content Rating`))

print(paste("Number of missing values in 'Content Rating':", cr_missing))
```
There are no missing values for Content rating.

```{r}
# Convert Last Updated to Date format
data_final$Last.Updated <- as.Date(data_final$Last.Updated, format = "%B %d, %Y")

# Verify the cleaning
print("\nSummary of Last.Updated after cleaning:")
print(summary(data_clean$Last.Updated))
```


#### After cleaning the Data
```{r}
str(data_final)
```




# Data Exploring and Visualization

#### Visualization for Price Distribution

```{r}
# Count Plot for the Price distribution
ggplot(data_final, aes(x=Price)) +
  geom_histogram(binwidth=2, fill="pink", color="black") +
   xlim(0, 500) + ylim(0, 500) +
  labs(title="Price Distribution", x="Price", y="Frequency") +
  theme_minimal()

```

The data is highly skewed as there are many zero price entries.

```{r}
# Boxplot for the same
ggplot(data_final, aes(y=Price)) +
  geom_boxplot(outlier.colour = "red", outlier.shape = 16, outlier.size = 1, fill="pink", color="black") +
  labs(title="Price Boxplot", y="Price") +
  theme_minimal()
```

#### Checking outliers for Price

```{r}
outlierKD2 <- function(df, var, rm = FALSE, boxplt = FALSE, histogram = TRUE, qqplt = FALSE) {
  dt <- df  # Duplicate the dataframe for potential alteration
  var_name <- eval(substitute(var), eval(dt))
  na1 <- sum(is.na(var_name))
  m1 <- mean(var_name, na.rm = TRUE)
  colTotal <- boxplt + histogram + qqplt  # Calculate the total number of charts to be displayed
  par(mfrow = c(2, max(2, colTotal)), oma = c(0, 0, 3, 0))  # Adjust layout for plots
  
  # Q-Q plot with custom title
  if (qqplt) {
    qqnorm(var_name, main="Q-Q plot without Outliers")
    qqline(var_name)
  }
  
  # Histogram with custom title
  if (histogram) { 
    hist(var_name,main = "Histogram without Outliers", xlab = NA, ylab = NA) 
  }
  
  # Box plot with custom title
  if (boxplt) { 
    boxplot(var_name, main= "Box Plot without Outliers")
  }
  
  # Identify outliers
  outlier <- boxplot.stats(var_name)$out
  mo <- mean(outlier)
  var_name <- ifelse(var_name %in% outlier, NA, var_name)
  
  # Q-Q plot without outliers
  if (qqplt) {
    qqnorm(var_name, main="Q-Q plot with Outliers")
    qqline(var_name)
  }
  
  # Histogram without outliers
  if (histogram) { 
    hist(var_name, main = "Histogram with Outliers", xlab = NA, ylab = NA) 
  }
  
  # Box plot without outliers
  if (boxplt) { 
    boxplot(var_name, main = "Boxplot with Outliers") 
  }
  
  # Add the title for the overall plot section if any plots are displayed
  if (colTotal > 0) {
    title("Outlier Check", outer = TRUE)
    na2 <- sum(is.na(var_name))
    cat("Outliers identified:", na2 - na1, "\n")
    cat("Proportion (%) of outliers:", round((na2 - na1) / sum(!is.na(var_name)) * 100, 1), "\n")
    cat("Mean of the outliers:", round(mo, 2), "\n")
    cat("Mean without removing outliers:", round(m1, 2), "\n")
    cat("Mean if we remove outliers:", round(mean(var_name, na.rm = TRUE), 2), "\n")
  }
}

```

```{r}
#outlier function is defined in previous chunck of code.
outlier_check_price = outlierKD2(data_final, Price, rm = FALSE, boxplt = TRUE, qqplt = TRUE)
```

The price values in the dataset, including both typical and extreme values, are valid observations for our analysis. As such, removing these outliers may not be beneficial for our study.

```{r}
#To check the value ranges
table(data_final$Price)
```
As aldready mentioned, there are 8903 free apps (More apps with price as 0).


#### Visualization for Type Distribution


```{r}
# Bar Plot for the Type Distribution
ggplot(data_final, aes(x = Type)) +
  geom_bar(fill = "pink", color = "black") +
  labs(title = "Distribution of App Types (Free vs Paid)", x = "Type", y = "Count") +
  theme_minimal()
```
As it is clear, there are more free apps.

```{r}
#Display statistics for the Price of apps grouped by their Type
data_final$Type <- as.factor(data_final$Type)


summary_by_type <- data.frame(
  Type = levels(data_final$Type),
  Min_Price = tapply(data_clean$Price, data_clean$Type, min, na.rm = TRUE),
  Max_Price = tapply(data_clean$Price, data_clean$Type, max, na.rm = TRUE),
  Mean_Price = tapply(data_clean$Price, data_clean$Type, mean, na.rm = TRUE),
  Median_Price = tapply(data_clean$Price, data_clean$Type, median, na.rm = TRUE)
)


print(summary_by_type)
```

```{r}
#Scatter plot for price distribution by app type
ggplot(data_final, aes(x = Type, y = Price, fill = Type)) +
  geom_boxplot() +
  labs(title = "Price Distribution by App Type", 
       x = "App Type", 
       y = "Price ($)") +
  theme_minimal()
```

#### Histogram for price distribution by App Type

```{r}
ggplot(data_final, aes(x = Price, fill = Type)) +
  geom_histogram(binwidth = 60, alpha = 0.7, position = "identity") +
  facet_wrap(~ Type) +
  labs(title = "Price Distribution by App Type", 
       x = "Price ($)", 
       y = "Count") +
  theme_minimal()
```

Upon analyzing the price distribution across different app types, we found that some values in the Type column do not accurately represent the app prices (from above plot). Since we can fully rely on the Price values for our analysis, the Type column is seemed unnecessary.

Hence, Removing the Type column...

#### Dropping the Type column
```{r}
#Using subset function
data_final <- subset(data_final, select = -Type)
```

```{r}
#After removing the Type column and duplicated values
str(data_final)
```

##### The Type column is successfully removed.

Let's do bivariate analysis on price and other variables starting from here.

#### Visualization for Price vs Installs 

```{r ST3}
#Plotting a scatter plot between Price and installs
ggplot(data_final, aes(x=Price, y=log(data_clean$Installs))) +
  geom_point(color = 'red', size = 1, alpha = 0.5) + 
  geom_smooth(method = 'lm', color = 'blue', se = FALSE) +
  labs(title = "Price vs Installs", x = "Price (USD)", y = "Number of Installs") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
From the scatter plot, we can see that there are more number of installations with price value 0. 

```{r}
# Categorize the apps as "Free" or "Paid" based on Price
Price_Category <- ifelse(data_final$Price == 0, "Free", "Paid")
str(data_final$Price)
str(Price_Category)
#str(log(data_clean$Installs))

```
For a better visualization, we are categorizing price values 0 as free apps and plotting abox plot. 
```{r}
# Box plot of Price Category vs. log-transformed Installs
ggplot(data_final, aes(x = Price_Category, y = log(data_clean$Installs))) +
  geom_boxplot(fill = "lightblue", color = "darkblue", alpha = 0.6) +
  labs(title = "Price Categories vs. Log-Transformed Installs", 
       x = "Price Category", 
       y = "Log(Installs)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  
```

"Free" apps tend to have more installs than "Paid" apps. The difference between the means on the log scale is estimated to be between 3.47 and 3.97.

```{r}
# Categorize the apps as "Free" or "Paid" based on Price
Price_Category <- ifelse(data_final$Price == 0, "Free", "Paid")
str(data_final$Price)
str(Price_Category)
#str(data_final$log(data_clean$Installs))

table(Price_Category)

```

```{r}
# Add Price_Category to data_final
data_duplicate <- data_final
data_duplicate$Price_Category <- ifelse(data_final$Price == 0, "Free", "Paid")

# Create a summarized table for Price_Category and log_Installs
summary_table <- data_duplicate %>%
  group_by(Price_Category) %>%
  summarise(Average_Log_Installs = mean(log(data_clean$Installs), na.rm = TRUE),
            Count = n())

# View the summarized table
kable(summary_table, format = "html", col.names = c("Price Category", "Mean Log(Installs)", "App Count")) %>%
  kable_styling(full_width = FALSE, position = "center") 

```

#### Visualization for Price vs Reviews & Rating

```{r}
# Plot Price vs. Reviews
ggplot(data_final, aes(x=Price, y=Reviews)) +
  geom_point(color = 'blue') +
  geom_smooth(method = 'lm', color = 'red', se = FALSE) +
  labs(title = "Price vs Reviews", x = "Price (USD)", y = "Number of Reviews") +
  theme_minimal() + 
  theme(
    panel.background = element_rect(fill = "white"),  # Set panel background to white
    plot.background = element_rect(fill = "white"),   # Set plot background to white
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Plot Price vs. Rating
ggplot(data_final, aes(x=Price, y=Rating)) +
  geom_point(color = 'green') +
  geom_smooth(method = 'lm', color = 'red', se = FALSE) +
  labs(title = "Price vs Rating", x = "Price (USD)", y = "Rating") +
  theme_minimal() + 
  theme(
    panel.background = element_rect(fill = "white"),  # Set panel background to white
    plot.background = element_rect(fill = "white"),   # Set plot background to white
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```

Price vs Reviews with installation: Cheaper products tend to have more
reviews, indicating higher popularity or more frequent purchases. In
contrast, expensive products tend to have fewer reviews, possibly
because fewer people buy higher-priced items.

Price vs Ratings with installation: Price does not strongly affect the
average rating, but there is a slight trend where lower-priced products
have more variation in ratings, while higher-priced products tend to
receive more consistent ratings around 4. May be higher price apps are
meeting the customer expectations.

 
#### Visualization for Price vs Reviews vs Installs

```{r}
# Scatter plot of Price vs. Ratings with log_Installs as  color
ggplot(data_final, aes(x = Price, y = Rating,color = log(data_clean$Installs))) +
  geom_point(alpha = 0.6) +
  scale_color_gradient(low = "blue", high = "red") +  
  labs(title = "Price vs. Ratings with Installs as Color by Price", 
       x = "Price", 
       y = "Rating", 
       color = "log(Installs)") +
  theme_minimal()

# Scatter plot of Price vs. Reviews with log_Installs as color
ggplot(data_final, aes(x = Price, y = Reviews,color = log(data_clean$Installs))) +
  geom_point(alpha = 0.6) +
  scale_color_gradient(low = "darkgreen", high = "yellow") +  
  labs(title = "Price vs. reviewss with Installs as Color by Price", 
       x = "Price", 
       y = "Reviews", 
       color = "log(Installs)") +
  theme_minimal()
```

Concluding: Apps with lower prices, have more ratings and installs while
apps priced higher tend to have fewer installs and more scattered
ratings. Similarly, for reviews.

#### Visualization for Price vs Size 

```{r}
# Plot Price vs Size
ggplot(data_final, aes(x=Price, y=Size)) +
  geom_point(color = 'red') + 
  geom_smooth(method = 'lm', color = 'blue', se = FALSE) +
  labs(title = "Price vs Size", x = "Price (USD)", y = "App Size (MB)") +
  theme_minimal() 
```


#### Visulization for Distribution of Installs

```{r A.J2}
# Create a copy of data_final for factor-level modifications
data_clean1_factor <- data_final  

# Define breakpoints and labels for the Installs factor
breaks <- c(0, 500, 1000, 2500, 5000, 10000, 25000, 50000, 100000, 300000, 1000000, 5000000,10000000,Inf)
labels <- c("0+","500+", "1K+", "2.5K+", "5K+", "10K+", 
            "25K+", "50K+", "100K+", "300K+", "1M+", "5M+","Above 10M+" )

# Convert Installs into a factor with the defined levels
data_clean1_factor$Installs <- cut(data_final$Installs, breaks = breaks, right = FALSE, labels = labels)

# Create a bar plot with the ordered factor
ggplot(data_clean1_factor, aes(x = Installs)) +
  geom_bar() +
  xlab("Installs") +
  ylab("Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  
  ggtitle("Distribution of App Installs")
```

This plot shows a common trend where many apps have limited user engagement, while a few high-performing apps achieve very high install counts, indicating a polarized distribution of app popularity.

### Visualization for Rating Distribution

```{r}
boxplot(data_final$Rating,ylab = "Rating", xlab = "Count",col = "Blue")
hist(data_clean$Rating, main="Histogram of Apps Rating after cleaning", xlab="Rating (count)", col = 'blue', breaks = 100 )
qqnorm(data_clean$Rating)
qqline(data_clean$Rating, col = "red")
```

Here, it could be seen the plots are much clearer but still skewed due
to other outliers from 1-3 rating but as these may be the reason from
which we could find why the apps are low rated hencecannot be removed
from our dataset.

### Visualization for Reviews

```{r}

boxplot(data_final$Reviews,ylab = "Reviews", xlab = "Count",col = 'Blue')
hist(data_final$Reviews, main="Histogram of Apps Reviews", xlab="Reviews (count)", col = 'blue', breaks = 100 )
ggplot(data_final, aes(x = log(Reviews))) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "Log-Transformed Histogram of Ratings", x = "Log(Rating)", y = "Count")

qqnorm(data_final$Reviews)
qqline(data_final$Reviews, col = "red")

```

Similar to the case of ratings the plots are skewed due to the outliers.
Hence, we can use the log plot of reviews for the visualisation which is
normalised version of Reviews. As they are skewed, they donot follow
normal distribution.

#### Review frequency table

```{r}
xkablesummary(data_final)
outlierKD2(data_final, Reviews)
```

To check which are outliers lets make sections of data that is create
bins to check which bins have maximum data, this would help us see how
reviews are distributed.

#### Binned reviews

Binning into equal count in each bin to check averge rating for each bin

```{r}
# Define the new custom breaks for bins
# Ensure there are no NA values


# Define new breaks for more even intervals
breaks <- c(0, 100, 500, 1000, 2500, 5000, 10000, 25000,50000,100000, 300000,1000000,Inf)

# Create a categorical variable based on the new breaks
Review_Category <- cut(data_final$Reviews, breaks = breaks, right = FALSE, 
                   labels = c("0+","100+", "500+", "1K+",
                              "2.5K+", "5K+", "10K+","25K+",
                              "50K+", "100K+","300K+","1M+"))

# Count the number of values in each bin
bin_counts <- as.data.frame(table(Review_Category))

# Rename the columns for clarity
colnames(bin_counts) <- c("Review_Category", "Count")

# Print the counts
print(bin_counts)

# Create a line plot of the binned counts
ggplot(bin_counts, aes(x = Review_Category, y = Count, group = 1)) +
  geom_line(color = "blue", size = 1) +
  geom_point(color = "blue", size = 3) +
  labs(title = "Count of Reviews by Review Category", 
       x = "Review Category", 
       y = "Count of Reviews") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability
```

Hence, high reviews can be observed in less apps and less reviews can be
observed in more apps which is expected.

#### Boxplots for Rating vs Reviews

```{r}
boxplot( data_final$Rating~ Review_Category, data = data_clean, 
        main = "Boxplot of Review Counts by Review Category", 
        xlab = "Review Category", 
        ylab = "Review Rating",
        las = 2,        # Rotate the x-axis labels for readability
        col = "lightblue")  # Optional: Set color for the boxplots

```

In this we could observe that, as reviews increase the median of rating
increased and the values clustered around higher ratings which could
show that high reviews, could mean a better rated app.

#### Mean value of Ratings for each Review bins

```{r}

# Calculate the mean Rating for each Review_Category
mean_ratings <- tapply(data_final$Rating, Review_Category, mean, na.rm = TRUE)

# Convert the result to a data frame for better readability
mean_ratings_df <- data.frame(Review_Category = names(mean_ratings), Mean_Rating = as.numeric(mean_ratings))

# Print the mean ratings for each review bin
print(mean_ratings_df)

# Define correct order of Review_Category as a factor
mean_ratings_df$Review_Category <- factor(mean_ratings_df$Review_Category, 
                                          levels = c("0+","100+", "500+", "1K+",
                                                     "2.5K+", "5K+", "10K+","25K+",
                                                     "50K+", "100K+", "300K+", "1M+"))

# Plot the mean ratings for each review bin in the correct order
ggplot(mean_ratings_df, aes(x = Review_Category, y = Mean_Rating)) +
  geom_bar(stat = "identity", fill = "steelblue") +  # Use bar plot
  labs(title = "Mean Rating by Review Category",
       x = "Review Category",
       y = "Mean Rating") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability



```

As we can see, the mean rating increases as the reviews increase.

#### Histogram for Reviews and Rating

```{r}
# Create a new data frame for plotting
plot_data <- data.frame(Rating = data_final$Rating, Review_Category = Review_Category)

# Create a histogram of Ratings, faceted by Review_Category
ggplot(plot_data, aes(x = Rating)) +
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  facet_wrap(~ Review_Category, labeller = label_wrap_gen()) +  # Facet by Review_Category
  theme_minimal() +
  labs(title = "Histograms of Ratings by Review Category", x = "Rating", y = "Frequency")
```

This is another representation of ratings vs reviews.

#### Visualization for Installs vs Size

```{r}
ggplot(data_clean, aes(x = Size, y = log(Installs))) +
  geom_hex(bins = 30) +
  scale_fill_viridis_c() + # Adds color gradient
  labs(title = "Plot of App Size vs. Installs (Log Scale)",
       x = "Size (MB)",
       y = "Installs (Log Scale)") +
  theme_minimal()

```

This analysis shows that apps with medium file sizes (around 20-50 MB) tend to be more popular and get downloaded more often. On the other hand, larger apps (over 75 MB) don’t get downloaded as much, possibly because they take up more space on devices or are slower to download.

#### Visualization for Reviews vs Installs

```{r A.J3}

# Scatter plot for Installs vs Reviews
ggplot(data_clean1_factor, aes(x = Review_Category, y = Installs)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Add a regression line
  labs(title = "Scatter Plot of Installs vs Reviews", 
       x = "Number of Reviews", 
       y = "Number of Installs") +
  theme_minimal()

```


This scatter plot shows that as apps get more downloads, they tend to get more reviews from users. Most apps fall in the lower range of downloads (like 0 to 50K installs), meaning they get a moderate number of reviews. Popular apps with over a million downloads often have thousands of reviews, showing strong user engagement. However, very few apps reach extremely high review counts (like 100K+ reviews), indicating that only a few apps become extremely popular. In short, the more installs an app has, the more likely it is to gather user feedback in the form of reviews.


#### Visualisation of Mean for different Install Categories
```{r}
# Calculate the mean Rating for each Review_Category
mean_ratings <- tapply(data_final$Rating, data_clean1_factor$Installs, mean, na.rm = TRUE)

# Convert the result to a data frame for better readability
mean_ratings_df <- data.frame(Installs = names(mean_ratings), Mean_Rating = as.numeric(mean_ratings))

# Print the mean ratings for each review bin
print(mean_ratings_df)

mean_ratings_df$Installs = factor(mean_ratings_df$Installs, levels = c(0,1,5,10,50,100,500,1000,5000,10000,50000,100000,500000,1000000,5000000,10000000,50000000,100000000,500000000,1000000000))

# Plot the mean ratings for each review bin in the correct order
ggplot(mean_ratings_df, aes(x = Installs, y = Mean_Rating)) +
  geom_bar(stat = "identity", fill = "steelblue") +  # Use bar plot
  labs(title = "Mean Rating by Install Category",
       x = "Installs Category",
       y = "Mean Rating") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for readability

```
Observing the flucuation of Rating for different Installs it could be seen that there is no constant increase or deacrease trend seen for Installs and rating, which could be expected as more Rating doesnot necessarily mean more Installs. But high Installs and high Rating could be seen as good app.

#### Visualization for Rating vs Installs
```{r A.J4}
# Scatter plot of log-transformed Installs vs. Rating
ggplot(data_final, aes(x = log(Installs) , y = Rating)) +
  geom_point(color = "blue", alpha = 0.6) +
  geom_smooth(method = "lm", color = "red", se = FALSE) +  # Add a regression line
  labs(title = "Log-Transformed Installs vs. Rating", 
       x = "Rating", 
       y = "Installs") +
  theme_minimal()

```

The scatter plot shows a weak positive correlation between app installs and ratings, as indicated by the nearly flat red trend line. Data points are clustered at specific rating levels, suggesting many apps share similar ratings but vary significantly in install counts. The x-axis range, extending to 20, is unusual for typical rating scales (e.g., 1-5), possibly indicating data irregularities or transformations. The y-axis, log-transformed, reveals a wide distribution in install counts. Overall, ratings seem to have minimal impact on installs, and the data’s clustering suggests further examination of the rating scale may be necessary.

#### Visualization for Rating vs Installs by Category

```{r A.J5, echo=FALSE, fig.width=12, fig.height=8, out.width='100%', fig.align='center'}

# Plot the combined graph with different colors based on Rating
ggplot(data_final, aes(x = log(data_clean$Installs), y = Rating)) +
  geom_point(aes(color = as.factor(Rating), shape = Category), alpha = 0.6, size = 3) +  # Points colored by Rating and shaped by Category
  scale_color_discrete(name = "Rating") +  # Discrete color scale
  labs(title = "Rating vs Installs (Log-Transformed Installs) by Category",
       x = "Log of Installs", y = "Rating") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  guides(shape = guide_legend(title = "Category"))  # Add legend title for Category

```

This scatter plot illustrates the relationship between log-transformed installs and ratings across app categories. Each category has distinct symbols and colors, showing varying distributions in ratings and installs. Higher-rated apps (around 4-5) are more densely populated across several categories, while lower-rated apps are sparse. Some categories, such as "LIFESTYLE" and "FINANCE," have a broad range of installs and ratings, while others are tightly clustered. The spread of installs varies widely, especially among apps with similar ratings, suggesting that category influences install counts significantly. Overall, higher ratings correlate with greater install variability across categories.

#### Visualization for Category Distribution

```{r}
category_counts <- table(data_final$Category)

# Convert to data frame for plotting
category_counts_df <- as.data.frame(category_counts)
colnames(category_counts_df) <- c("Category", "Frequency") 

ggplot(category_counts_df, aes(x = reorder(Category, Frequency), y = Frequency)) + 
  geom_bar(stat = "identity", fill = "#1f3374") +
  geom_text(aes(label = Frequency), vjust = 0.5, hjust=1, size=2.5, color='#f8c220') +
  coord_flip() +  
  labs(title = "Distribution of Categories", x = "Category", y = "Frequency") +
  theme_minimal() +
   theme(
    plot.background = element_rect(fill = "#efefef", color = NA),
    panel.background = element_rect(fill = "#efefef", color = NA),
    axis.text.y = element_text(size = 5.5)
  )
```

AS it can be seen from the graph above, most of the apps in the dataset belong to the Family and Game, tools category, and Beauty,comics have the least number of apps. 


#### Visualization for Category vs. Installs

Below is a boxplot show the distribution of number of installs for each
category order by mean from highest to lowest. 

```{r}
ggplot(data_clean, aes(x = reorder(Category, log(data_final$Installs),  FUN = mean), y = log(data_clean$Installs))) +
  geom_boxplot(outlier.color = "#f05555", outlier.shape = 1, color='#1f3374', fill="#efefef") +  # Red outliers for emphasis
  coord_flip() +  # Flip for better readability
  scale_y_log10() +
  theme_minimal() +
  labs(title = "Distribution of Installs by Category",
       x = "Category",
       y = "Number of Installs (Log Scale)") +
    theme(
    plot.background = element_rect(fill = "#efefef", color = NA),
    panel.background = element_rect(fill = "#efefef", color = NA),
    axis.text.y = element_text(size = 5.5)
  )
```
It can be seen from the graph that, on average, Entertainment apps receive the highest number of installations, followed by Education, Game, Photography, and Weather apps. In contrast, Art & Design apps have the fewest installations.

#### Visualization for Category vs. App Size


```{r}
#convert_size <- function(size) {
#    size <- gsub(",", "", size)  # Remove commas
#    size <- tolower(size)  # Make lowercase for consistency
      
      # Handle "varies with device" by assigning NA
#    if (size == "varies with device") return(NA)
      
      # Convert "k" to MB (1 MB = 1000 KB)
 #   if (grepl("k", size)) return(as.numeric(gsub("k", "", size)) / 1000)
      
      # Convert "M" to numeric MB
  #  if (grepl("m", size)) return(as.numeric(gsub("m", "", size)))
      
      # Handle numeric values directly (e.g., "1000+")
   # if (grepl("\\d+\\+", size)) return(as.numeric(gsub("\\+", "", size)) / 1000)
      
      # Default case: return as numeric if possible
    #return(as.numeric(size))
    #}
```

Below is the figure showing the distribution of app sizes in each category. 

```{r}
#df_clean <- data_clean %>%
 # mutate(Size = sapply(Size, convert_size)) %>%
#  filter(!is.na(Size))

# Plot the histogram with faceting by category
ggplot(data_clean, aes(x = Size)) +
  geom_histogram(binwidth = 5, fill = "#304ba6", color = "black") +
  facet_wrap(~ Category, scales = "free_y") +
  theme_minimal() +
  labs(
    title = "Distribution of App Sizes by Category",
    x = "Size (MB)",
    y = "Count"
  ) +
  theme(
    strip.text = element_text(size = 5),
    axis.text.x = element_text(size = 7, angle = 45, hjust = 1)
  )

str(data_clean)

```



```{r}
ggplot(data_clean, aes(x = reorder(Category, Size, FUN = median), y = Size)) + 
  geom_boxplot(outlier.color = "#f05555", outlier.shape = 1) + 
  coord_flip() + 
  theme_minimal() + 
  labs(
    title = "Boxplot of App Sizes by Category (Ordered by Median)", 
    x = "Category", 
    y = "Size (MB)"
  ) + 
  theme(
    strip.text = element_text(size = 8), 
    axis.text.x = element_text(size = 7, angle = 45, hjust = 1)
  )

```

As it can be seen from the two figures above, most categories exhibit right-skewed app sizes, with the majority being under 50MB. However, the Game category stands out with a significantly larger median app size compared to other categories.

#### Visualization for Category vs. Reviews


Below is the graph displaying the distribution of reviews left by users for each category.

```{r}

df_aggregated <- data_final %>% 
  group_by(Category) %>% 
  summarise(Total_Reviews = sum(Reviews, na.rm = TRUE))

#df_aggregated

```

```{r}
# Plot the total reviews by category using a bar chart
ggplot(df_aggregated, aes(x = reorder(Category, -Total_Reviews), y = log10(Total_Reviews))) + 
  geom_bar(stat = "identity", fill = "#1f3374") + 
  labs(
    title = "Log-Scaled Total Reviews by Category", 
    x = "Category", 
    y = "Log10(Total Number of Reviews)"
  ) + 
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```
AS it can be seen that game apps have most reviews while events apps have the least reviews.

#### Histogram for Category vs. Rating

Below is the figure demonstrating the distribution of number of rating for each category. 

```{r}
ggplot(data_final, aes(x = Rating)) + 
  geom_histogram(binwidth = 0.5, fill = "#1f3374", color='#efefef') + 
  facet_wrap(~ Category, scales = "free_y") +  # Facet by Category with independent y-axis
  scale_x_continuous(limits = c(1, 5), breaks = seq(1, 5, by = 0.5)) +  # Restrict x-axis to 1-5
  theme_minimal() + 
  labs(
    title = "Distribution of Ratings by Category", 
    x = "Rating", 
    y = "Count"
  ) + 
  theme(
    strip.text = element_text(size = 5),  # Adjust facet label size
    axis.text.x = element_text(size = 5, angle = 45, hjust = 1),  # Rotate x-axis labels
    plot.title = element_text(hjust = 0.5)  # Center the plot title
  )



```
As illustrated in the graph above, all categories have app ratings that range between 4.0 and 5.0.


#### Visualization for Android Version

Below is the figure showing the distribution of Android versions.

```{r}
extract_version <- function(version) {
  version <- tolower(version)  # Make lowercase for consistency
  
  # Handle "Varies with device" and "NaN"
  if (version == "varies with device" || version == "nan") return(NA)
  
  # Extract the first version in case of ranges (e.g., "4.1 - 7.1.1" -> "4.1")
  first_version <- strsplit(version, "[- ]")[[1]][1]
  
  # Remove "and up" if present (e.g., "4.0 and up" -> "4.0")
  first_version <- gsub("and up", "", first_version)
  
  return(as.numeric(first_version))  # Convert to numeric
}



```

```{r}
df_clean <- data_final %>%
  mutate(Android_Ver = sapply(Android.Ver, extract_version)) %>%
  filter(!is.na(Android_Ver))  # Remove rows with NA in Android_Ver

android_installs <- data_final %>% 
  group_by(Android.Ver) %>% 
  summarize(Total_Installs = sum(Installs, na.rm = TRUE))


```

```{r}
ggplot(df_clean, aes(x = Android_Ver)) + 
  geom_histogram(binwidth = 0.5, fill = "#1f3374", color='#efefef') + 
  scale_x_continuous(breaks = seq(1, 8, by = 1.0)) +  # Set x-axis ticks from 1.0 to 8.0
  theme_minimal() + 
  labs(
    title = "Distribution of Android Versions", 
    x = "Android Version", 
    y = "Count"
  ) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
As it can be seen that, the minimum required Android Version for most apps is 4.0 and up. 

```{r}
extract_version <- function(version) {
  version <- tolower(version)  # Make lowercase for consistency
  
  # Handle "Varies with device" and "NaN"
  if (version == "varies with device" || version == "nan") return(NA)
  
  # Extract the first version in case of ranges (e.g., "4.1 - 7.1.1" -> "4.1")
  first_version <- strsplit(version, "[- ]")[[1]][1]
  
  # Remove "and up" if present (e.g., "4.0 and up" -> "4.0")
  first_version <- gsub("and up", "", first_version)
  
  return(as.numeric(first_version))  # Convert to numeric
}

```

#### Bar plot for Android Version vs. Installs

Below is the graph showing the number of installs for each minimum required Android Version. 

```{r}
ggplot(data_final, aes(x = reorder(Android.Ver, Installs), y = Installs)) + 
  geom_bar(stat = "identity", fill = "#1f3374") + 
  coord_flip() +  # Flip coordinates for better readability
  scale_y_continuous(labels = scales::comma) +  # Format y-axis with commas
  theme_minimal() + 
  labs(
    title = "Total Installs by Android Version", 
    x = "Android Version", 
    y = "Total Installs"
  ) + 
  theme(
    axis.text.y = element_text(size = 8),  # Adjust y-axis text size
    plot.title = element_text(hjust = 0.5)  # Center the plot title
  )

```

It can be seen that the highest number of installation is when there is different requirements of the versions for the app to run. 

#### Boxplot for Android Version vs. Reviews

Below is the distribution of reviews for each minimum required Android Version.

```{r}
df_clean <- data_final %>% 
  filter(!is.na(Android.Ver) & !is.na(Reviews)) %>% 
  mutate(Scaled_Reviews = log10(Reviews + 1))
```

```{r}
ggplot(df_clean, aes(x = reorder(Android.Ver, Scaled_Reviews, FUN = median), y = Scaled_Reviews)) + 
  geom_boxplot(outlier.color = "#f05555", outlier.shape = 1) +  # Boxplot with red outliers
  coord_flip() +  # Flip coordinates for better readability
  theme_minimal() + 
  labs(
    title = "Distribution of Scaled Reviews by Android Version", 
    x = "Android Version", 
    y = "Scaled Reviews (Log10)"
  ) + 
  theme(
    axis.text.y = element_text(size = 8),  # Adjust y-axis text size
    plot.title = element_text(hjust = 0.5)  # Center the plot title
  )

```

It can be seen that the version from 4.1 to 7.1.1 have the highest number of reviews, whiel version from 5.0 to 7.1.1 have the least number of reviews. 


####  Histogram for Android Version vs. Rating

Below is the plot showing the number of ratings for each Android Version. 

```{r}
ggplot(df_clean, aes(x = Rating, fill = Android.Ver)) + 
  geom_histogram(binwidth = 0.5, position = "stack", color = "black", alpha = 0.7) + 
  scale_x_continuous(breaks = seq(1, 5, by = 0.5)) +  # Set x-axis breaks
  theme_minimal() + 
  labs(
    title = "Histogram of Ratings by Android Version", 
    x = "Rating", 
    y = "Count"
  ) + 
  theme(
    axis.text.x = element_text(size = 8), 
    axis.text.y = element_text(size = 8), 
    plot.title = element_text(hjust = 0.5)  # Center the plot title
  )

```
It can be seen that most Android Version have ratings range between 4.0 and 5.0.


#### Distribution for Content.Rating

```{r}
# Clean and prepare the Last Updated  and Content column
data_final <- data_final %>%
  mutate(
    Content.Rating = as.factor(Content.Rating)
  )

# 1. Content Rating Distribution
content_rating_dist <- table(data_final$Content.Rating)
print("Content Rating Distribution:")
print(content_rating_dist)
```

#### Visualization for Content Rating

```{r}
# Bar plot for Content Rating
ggplot(data_final, aes(x = Content.Rating)) +
  geom_bar(fill = "skyblue") +
  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
  labs(title = "Distribution of App Content Ratings",
       x = "Content Rating",
       y = "Number of Apps") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Everyone is the most dominant Category with 81.82% of all apps and Adults 18+ being most least significant category with about 0.03% of overall app population


```{r}
# Last Updated Analysis
# Create summary of updates by month and year
updates_by_month <- data_final %>%
  mutate(
    update_month = format(Last.Updated, "%Y-%m"),
    update_year = year(Last.Updated)
  ) %>%
  group_by(update_month) %>%
  summarize(count = n()) %>%
  arrange(update_month)
```

```{r}
# Plot updates over time
#ggplot(updates_by_month, aes(x = as.Date(paste0(update_month, "-01")), y = count)) +
  #geom_line(color = "blue") +
  #geom_point(color = "red") +
  #labs(title = "Number of App Updates Over Time",
  #     x = "Date",
  #     y = "Number of Updates") +
  #theme_minimal() +
 # theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The number of updates have drastically increased from the end of 2017

```{r}
# Content Rating and Update Frequency Relationship
update_frequency_by_rating <- data_final %>%
  group_by(Content.Rating) %>%
  summarize(
    avg_last_update = mean(Last.Updated),
    median_last_update = median(Last.Updated),
    n_apps = n()
  )
print("\nUpdate Frequency by Content Rating:")
print(update_frequency_by_rating)
```

```{r}
# Content Rating Basic Analysis
#print("Basic Content Rating Analysis:")
#content_rating_counts <- table(data_final$Content.Rating)
#print(content_rating_counts)

# Basic bar plot for Content Rating
#ggplot(data_final, aes(x = Content.Rating)) +
#  geom_bar(fill = "skyblue") +
#  geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
#  labs(title = "Distribution of App Content Ratings",
#       x = "Content Rating",
#       y = "Number of Apps") +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1))
# 
# # Calculate percentages
# content_rating_percentages <- prop.table(content_rating_counts) * 100
# print("\nContent Rating Percentages:")
# print(round(content_rating_percentages, 2))
# 
# # 1.2 Last Updated Basic Analysis
# data_final$Last.Updated <- as.Date(data_final$Last.Updated, format = "%B %d, %Y")
# 
# print("\nLast Updated Summary Statistics:")
# summary(data_final$Last.Updated)
```

```{r}

# Time-based Analysis
data_final <- data_final %>%
  mutate(
    update_year = year(Last.Updated),
    update_month = month(Last.Updated),
    update_quarter = quarter(Last.Updated),
    days_since_update = as.numeric(difftime(max(Last.Updated), Last.Updated, units = "days"))
  )

# Monthly update pattern
monthly_updates <- data_final %>%
  group_by(update_year, update_month) %>%
  summarize(count = n()) %>%
  mutate(date = as.Date(paste(update_year, update_month, "01", sep = "-")))

ggplot(monthly_updates, aes(x = date, y = count)) +
  geom_line(color = "blue") +
  geom_point() +
  labs(title = "App Updates Over Time",
       x = "Date",
       y = "Number of Updates") +
  theme_minimal()

# 2.2 Content Rating Distribution by Update Quarter
ggplot(data_final, aes(x = factor(update_quarter), fill = Content.Rating)) +
  geom_bar(position = "dodge") +
  labs(title = "Content Rating Distribution by Quarter",
       x = "Quarter",
       y = "Count") +
  theme_minimal()
```
```{r}
# 3.1 Update Frequency Analysis by Content Rating
update_patterns <- data_final %>%
  group_by(Content.Rating) %>%
  summarize(
    avg_days_since_update = mean(days_since_update),
    median_days_since_update = median(days_since_update),
    sd_days_since_update = sd(days_since_update),
    n_apps = n(),
    cv = sd(days_since_update) / mean(days_since_update) * 100  # Coefficient of Variation
  ) %>%
  arrange(avg_days_since_update)

print("\nUpdate Patterns by Content Rating:")
print(update_patterns)


# 3.3 Advanced Visualization - Heatmap of Updates
update_heatmap_data <- data_final %>%
  group_by(update_month, Content.Rating) %>%
  summarize(count = n()) %>%
  spread(Content.Rating, count)

# Convert to matrix for heatmap
update_matrix <- as.matrix(update_heatmap_data[,-1])
rownames(update_matrix) <- month.abb[update_heatmap_data$update_month]

# Create heatmap
heatmap(update_matrix, 
        Colv = NA, 
        Rowv = NA,
        scale = "column",
        col = colorRampPalette(c("white", "steelblue"))(50),
        main = "Update Pattern Heatmap by Content Rating",
        xlab = "Content Rating",
        ylab = "Month")

# 3.4 Time Series Decomposition
# Focus on Everyone category as an example
#everyone_ts <- monthly_updates %>%
#  filter(count > 0) %>%
#  select(count) %>%
#  ts(frequency = 12)

#decomposed <- decompose(everyone_ts)
#plot(decomposed)

# 3.4 Update Velocity Analysis
update_velocity <- data_final %>%
  group_by(Content.Rating) %>%
  summarize(
    update_velocity = n() / n_distinct(update_month),
    total_apps = n()
  ) %>%
  arrange(desc(update_velocity))

print("\nUpdate Velocity by Content Rating:")
print(update_velocity)
```
###Observation for Update Frequency Velocity Analysis:
This column represents the average number of updates per app for each content rating category. It reflects how frequently apps in each category receive updates.

```{r}
# 1. Update Cycle Analysis
data_final <- data_final %>%
  mutate(
    Last.Updated = as.Date(Last.Updated, format = "%B %d, %Y"),
    day_of_week = wday(Last.Updated, label = TRUE),
    week_of_year = week(Last.Updated),
    month_of_year = month(Last.Updated, label = TRUE),
    season = case_when(
      month_of_year %in% c("Dec", "Jan", "Feb") ~ "Winter",
      month_of_year %in% c("Mar", "Apr", "May") ~ "Spring",
      month_of_year %in% c("Jun", "Jul", "Aug") ~ "Summer",
      TRUE ~ "Fall"
    )
  )

# Day of Week Update Pattern by Content Rating
dow_pattern <- data_final %>%
  group_by(Content.Rating, day_of_week) %>%
  summarise(count = n()) %>%
  group_by(Content.Rating) %>%
  mutate(percentage = count/sum(count) * 100)

ggplot(dow_pattern, aes(x = day_of_week, y = percentage, fill = Content.Rating)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~Content.Rating) +
  labs(title = "Update Day Preferences by Content Rating",
       x = "Day of Week",
       y = "Percentage of Updates") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# 2. Update Interval Analysis
update_intervals <- data_final %>%
  group_by(Content.Rating) %>%
  arrange(Last.Updated) %>%
  mutate(days_between_updates = as.numeric(Last.Updated - lag(Last.Updated))) %>%
  summarise(
    mean_interval = mean(days_between_updates, na.rm = TRUE),
    median_interval = median(days_between_updates, na.rm = TRUE),
    std_dev = sd(days_between_updates, na.rm = TRUE),
    cv = std_dev / mean_interval * 100  # Coefficient of Variation
  )

print("Update Interval Analysis:")
print(update_intervals)
```


```{r}
# 3. Seasonal Update Intensity
seasonal_intensity <- data_final %>%
  group_by(Content.Rating, season) %>%
  summarise(
    update_count = n(),
    update_intensity = n() / n_distinct(Last.Updated)
  ) %>%
  arrange(Content.Rating, desc(update_intensity))

# Visualization of seasonal patterns
ggplot(seasonal_intensity, aes(x = season, y = update_intensity, fill = Content.Rating)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Seasonal Update Intensity by Content Rating",
       x = "Season",
       y = "Update Intensity") +
  theme_minimal()
```
```{r}
# 4. Update Clustering Analysis
#update_features <- data_final %>%
#  group_by(Content.Rating) %>%
#  summarise(
#    mean_week = mean(week_of_year),
#    std_week = sd(week_of_year),
#    update_frequency = n(),
#    weekend_ratio = sum(day_of_week %in% c("Sat", "Sun")) / n()
#  )

# Normalize the features
#update_features_norm <- scale(update_features[,-1])
#rownames(update_features_norm) <- update_features$Content.Rating

# Perform hierarchical clustering
#update_clusters <- hclust(dist(update_features_norm))
#plot(update_clusters, main = "Hierarchical Clustering of Content Ratings by Update Patterns")
```
```{r}

# 6. Update Consistency Score
#onsistency_score <- data_final %>%
#  group_by(Content.Rating) %>%
#  summarise(
#    total_updates = n(),
#    unique_days = n_distinct(Last.Updated),
#   consistency_score = (total_updates / unique_days) * 
#      (1 - sd(as.numeric(day_of_week)) / 7)  # Normalized consistency metric
#  ) %>%
#  arrange(desc(consistency_score))

#print("\nUpdate Consistency Scores:")
#print(consistency_score)
```


```{r}

# Convert Last.Updated to numeric (days since reference date) if not already done
# reference_date <- min(data_final$Last.Updated, na.rm = TRUE)  # Reference date
# data_final$Days.Since.Update <- as.numeric(data_final$Last.Updated - reference_date)
# 
# # Perform the Kolmogorov-Smirnov test on the numeric 'Days.Since.Update' values
# content_ratings <- unique(data_final$Content.Rating)
# ks_results <- data.frame(
#   rating1 = character(),
#   rating2 = character(),
#   p_value = numeric()
# )
# 
# for (i in 1:(length(content_ratings)-1)) {
#   for (j in (i+1):length(content_ratings)) {
#     # Extract groups, removing NA values
#     group1 <- na.omit(data_final$Days.Since.Update[data_final$Content.Rating == content_ratings[i]])
#     group2 <- na.omit(data_final$Days.Since.Update[data_final$Content.Rating == content_ratings[j]])
#     
#     # Check if both groups have enough data for comparison
#     if(length(group1) > 1 && length(group2) > 1) {
#       ks_test <- ks.test(group1, group2)
#       ks_results <- rbind(ks_results, 
#                           data.frame(rating1 = content_ratings[i],
#                                      rating2 = content_ratings[j],
#                                      p_value = ks_test$p.value))
#     }
#   }
# }
# 
# print("\nKolmogorov-Smirnov Test Results:")
# print(ks_results[ks_results$p_value < 0.05,])

```



#### Visualization for Content Rating vs Installs

```{r}
# 1. Basic statistics for Installs by Content Rating
installs_by_rating <- data_final %>%
  group_by(Content.Rating) %>%
  summarise(
    mean_installs = mean(Installs, na.rm = TRUE),
    median_installs = median(Installs, na.rm = TRUE),
    total_installs = sum(Installs, na.rm = TRUE),
    n_apps = n()
  ) %>%
  arrange(desc(mean_installs))

print("Summary of Installs by Content Rating:")
print(installs_by_rating)

# 2. Visualize distribution of installs by content rating
ggplot(data_final, aes(x = Content.Rating, y = log10(Installs))) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "Distribution of App Installs by Content Rating",
       x = "Content Rating",
       y = "Log10(Number of Installs)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#### Visualization for Last Updated vs Installs
```{r}
data_analysis <- data_final %>%
  mutate(
    days_since_update = as.numeric(difftime(max(Last.Updated), Last.Updated, units = "days")),
    update_year = year(Last.Updated),
    update_month = month(Last.Updated)
  )


data_analysis <- data_analysis %>%
  mutate(update_recency = ifelse(days_since_update <= median(days_since_update),
                                "Recent Update", "Old Update"))

recent_vs_old <- data_analysis %>%
  group_by(Content.Rating, update_recency) %>%
  summarise(
    mean_installs = mean(Installs, na.rm = TRUE),
    median_installs = median(Installs, na.rm = TRUE),
    n_apps = n()
  )

print("\nComparison of Installs by Update Recency and Content Rating:")
print(recent_vs_old)


# 7. Visualization of update recency effect
ggplot(data_analysis, aes(x = Content.Rating, y = log10(Installs), fill = update_recency)) +
  geom_boxplot() +
  labs(title = "Install Distribution by Content Rating and Update Recency",
       x = "Content Rating",
       y = "Log10(Number of Installs)",
       fill = "Update Recency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```


#### Visualization for Last Updated vs Content Rating vs Installs 
```{r}
# 3. Timeline analysis: Average installs over time by content rating
installs_timeline <- data_final %>%
  group_by(Content.Rating, Last.Updated) %>%
  summarise(avg_installs = mean(Installs, na.rm = TRUE)) %>%
  ungroup()

ggplot(installs_timeline, aes(x = Last.Updated, y = log10(avg_installs), color = Content.Rating)) +
  geom_smooth(method = "loess", se = FALSE) +
  labs(title = "Average App Installs Over Time by Content Rating",
       x = "Last Updated Date",
       y = "Log10(Average Installs)") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


# Statistical Tests

#### Statistical test for Installs and Price 

```{r}
# Check for missing values and ensure no negative/zero values in log_Installs
#data_final <- data_final %>%
  #filter(!is.na(Installs), Installs > 0)  # Remove missing values and zeros in Installs

# Apply log transformation, adding 1 to avoid log(0)
#data_final$log_Installs <- log(data_final$Installs + 1)

# Ensure Price_Category has no missing values
#data_final <- data_final %>%
 #filter(!is.na(Price_Category))

#Perform t-test on log-transformed Installs by Price Category
#t_test_result <- t.test(log_Installs ~ Price_Category, data = data_final, var.equal = FALSE)

#Print t-test results
#print(t_test_result)

```

There is a statistically significant difference between the number of
installs for "Free" and "Paid" apps, with the p-value being extremely
small.

From the above analysis, we can practically state that free apps are
more popular than paid apps, which can be considered true in the app
market.


#### T-Test for Reviews and Price 
```{r}
#Confirming with a t-test
# Perform t-test for Reviews between Free and Paid
t_test_reviews <- t.test(Reviews ~ Price_Category, data = data_final)

# Perform t-test for Rating between Free and Paid
t_test_rating <- t.test(Rating ~ Price_Category, data = data_final)

# Print the results
print(t_test_reviews)
print(t_test_rating)


```
* There is a statistically significant difference between the mean number of reviews for Free and Paid apps. Free apps have significantly more reviews on average.

* There is a statistically significant difference between the mean ratings for Free and Paid apps. Paid apps have slightly higher ratings on average, though the difference is small.


#### ANOVA Test for Reviews vs Ratings

The tests below are to test whether or not different review categories have
different average ratings.

```{r}
anova_result <- aov(Rating ~ as.factor(Review_Category), data = data_clean)
summary(anova_result)
```

According to p-value, it is significant hence we can say that the average rating for all review categories is not same.

#### Post Hoc Test

```{r}
# Perform Tukey's HSD
tukey_result <- TukeyHSD(anova_result)
tukey_result
# Convert the result to a data frame
tukey_df <- as.data.frame(tukey_result$`as.factor(Review_Category)`)

# Filter for significant p-values
significant_tukey <- tukey_df[tukey_df[4] < 0.05, ]

# Display the significant results
print(significant_tukey)


```

As we can see, the significant difference for average rating for
different review categories is between 0+ and 1M+ as expected.

For easier Ratings and Reviews vs Installs we can group Installs into
categories given

#### ANOVA test for Content Rating vs Installs 
```{r}
# 1. Encode content rating (e.g., as factor levels or one-hot encoding)
data_final$Content.Rating <- as.factor(data_final$Content.Rating)

data_final <- data_final %>%
  filter(!is.na(Installs) & Installs > 0)

# ANOVA test for difference in installs between content ratings
install_anova <- aov(log10(Installs) ~ Content.Rating, data = data_final)

print("\nANOVA test results for Installs by Content Rating:")
print(summary(install_anova))


```


ANOVA analysis : 
Revealed significant differences in install counts based on content rating (F(5, 9638) = 41.95, p < 2e-16). This indicates that various content ratings have a substantial impact on the number of installs, highlighting the importance of content quality and type in attracting users.


# Correlation 

#### Correlation for all variables in data_final
Lets convert all the categorical variables into factors and then convert into numerical dataframe for calucalting the correlation matrix 
```{r}
# Step 1: Create a copy of the original data without specific columns
columns_to_remove <- c("App", "Scaled_Reviews", "update_year", "update_month", 
                        "update_quarter", "days_since_update", "week_of_year", "Last.Updated","day_of_week","month_of_year","season")

data_numeric_or_factor <- data_final %>%
  select(-one_of(columns_to_remove))



# Step 2: Convert specified categorical columns to factors

data_factor <- data_numeric_or_factor

# Step 3: Identify categorical columns
categorical_columns <- sapply(data_numeric_or_factor, is.factor)

# Step 4: Convert each categorical variable to numeric
data_final_numeric <- data_numeric_or_factor  # Copy of the data
data_final_numeric[categorical_columns] <- lapply(data_numeric_or_factor[categorical_columns], 
                                                   function(x) as.numeric(as.factor(x)))


# Step 5: Calculate Pearson correlation
correlation_matrix <- cor(data_final_numeric,method = "pearson", use = "complete.obs")
print(correlation_matrix)

# Caluclate the spearman 
correlation_matrix1 <- cor(data_final_numeric, method = "spearman", use = "complete.obs")
print(correlation_matrix1)

# Step 6: Plot the correlation matrix
corrplot(correlation_matrix, method = "color", addCoef.col = "black")
corrplot(correlation_matrix1, method = "color", addCoef.col = "black")

```
As seen installs has the highest correlation with the reviews.

As we can see from the both pearson and spearman have relatively different correlation matrices and plots.
We can refer to the categorical variables correlation from the spearman.

### Correlation Reviews


```{r}
reviews_correlation_factor <- correlation_matrix[, "Reviews", drop = FALSE]

reviews_correlation_factor1 <- correlation_matrix1[, "Reviews", drop = FALSE]

# Print the correlation matrix for Reviews from numeric factor data
print(reviews_correlation_factor)

# Step 6: Create a correlation plot for Reviews in data_numeric_or_factor
corrplot(reviews_correlation_factor, method = "color", addCoef.col = "black", 
         title = "Correlation of Reviews with Other Variables (Factor Data)", 
         tl.col = "black", tl.srt = 45)


corrplot(reviews_correlation_factor1, method = "color", addCoef.col = "black", 
         title = "Correlation of Reviews with Other Variables (Factor Data)", 
         tl.col = "black", tl.srt = 45)


```

As seen reviews has the highest correlation(positive) with the installs and then in spearman correlation matrix it has high correlation(positive) with content rating and android version meaning


#### Correlation with Rating

```{r}
rating_correlation_factor <- correlation_matrix[, "Rating", drop = FALSE]

rating_correlation_factor1 <- correlation_matrix1[, "Rating", drop = FALSE]

# Print the correlation matrix for Reviews from numeric factor data
print(rating_correlation_factor)

# Step 6: Create a correlation plot for Reviews in data_numeric_or_factor
corrplot(rating_correlation_factor, method = "color", addCoef.col = "black", 
         title = "Correlation of Reviews with Other Variables (Factor Data)", 
         tl.col = "black", tl.srt = 45)


corrplot(rating_correlation_factor1, method = "color", addCoef.col = "black", 
         title = "Correlation of Reviews with Other Variables (Factor Data)", 
         tl.col = "black", tl.srt = 45)


```

Rating is not much correlated with any of the variables, only slightly positively correlated with reviews and installs which was also demonstrated through visualisation previously.

#### Correlation with Price 
```{r}
# Spearman correlation for Price
price_correlation_factor1 <- correlation_matrix1[, "Price", drop = FALSE]
print("Spearman Correlation of Price with Other Variables:")
print(price_correlation_factor1)

# Plot for Spearman correlation with Price
corrplot(price_correlation_factor1, method = "color", addCoef.col = "black", 
         title = "Correlation of Price with Other Variables (Spearman)", 
         tl.col = "black", tl.srt = 45)

```

Price vs. Log_Installs: -0.06, suggesting a very weak negative
relationship between price and the number of installs.


#### Correlation between time analysis variables VS Installs

```{r}

# Create a new data frame with relevant variables for correlation analysis
#correlation_data <- data_analysis %>%
#  select(days_since_update, update_year, update_month) %>%
#  mutate(log_installs = log10(data_final$Installs))

# Calculate the correlation matrix
#correlation_matrix <- cor(correlation_data, method = "spearman", use = "complete.obs")

# Print the correlation matrix
#print("Spearman Correlation Matrix:")
#corrplot(correlation_matrix, method = "color", 
#          col = colorRampPalette(c("red", "white", "blue"))(200),
#          type = "upper", 
#          tl.col = "black", tl.srt = 45, 
#          addCoef.col = "black", # Add correlation coefficients
#          number.cex = 0.7,      # Adjust size of numbers
#          title = "Correlation Matrix", # Title
#          mar = c(0, 0, 1, 0))   # Margins

```

Correlation Analysis:
A moderate negative correlation :(ρ=−0.3317) was found between the number of days since the last update and the log-transformed installs. This indicates that as the time since the last update increases, the number of installs tends to decrease. The relationship is statistically significant (p < 2.2e-16), suggesting that timely updates may be crucial for maintaining user engagement.

#### Chi-square Test for Content Rating vs Last Updated 
```{r}
# 3.2 Statistical Tests

# Chi-square test for independence
contingency_table <- table(data_final$Content.Rating, data_final$update_quarter)
chi_test <- chisq.test(contingency_table)
print("\nChi-square test for independence between Content Rating and Update Quarter:")
print(chi_test)

```
The P value is small signifying that there is statistically significant relationship between Content Rating and Last Updated quarter 


Implications
These findings suggest that regular updates are important for sustaining app installs, and that different content ratings can influence user engagement. Strategies aimed at timely updates and optimizing content ratings could enhance app performance and user acquisition.


##correlation between Installs Vs Size
```{r}
# Calculate Pearson correlation and perform the test
cor_test <- cor.test(data_clean$Size, data_clean$Installs, method = "pearson")

# Output the correlation coefficient and p-value
cor_test
```

According to the relational hypothesis testing:
1. Correlation Coefficient (cor):Pearson correlation coefficient is 0.0407. This indicates a very weak positive relationship between Size and Installs—meaning that as app size increases, installs slightly tend to increase as well, but the effect is minimal.

P-values: The p-value is 6.198e-05 (or 0.00006198), which is much smaller than the conventional significance level (e.g., 0.05). This low p-value means that we can reject the null hypothesis (that there is no correlation) and conclude that x and y are not independent.

Confidence Interval: The 95% confidence interval for the correlation coefficient is between 0.0208 and 0.0606. This range is quite narrow and close to zero, further confirming that while the relationship is significant, the strength of the correlation is very low.







